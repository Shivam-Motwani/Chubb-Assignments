{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6183367f-0cad-4210-98c5-08b384210921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bronze Layer Validation ===\nBronze records count: 1000\n=== Silver Layer Validation ===\nSilver valid records count: 651\nSilver records with incorrect total_amount: 126\nSilver quarantined records count: 349\n=== Gold Layer Validation ===\nGold records count: 30\nTotal amount in Silver: 264289\nTotal amount in Gold: 264289\nGold aggregation matches Silver totals\n=== Logging Validation ===\n+--------------+-----------------+----------------+---------+--------------------------+--------------------------+-----------------------------------+\n|pipeline_layer|records_processed|records_rejected|status   |start_ts                  |end_ts                    |remarks                            |\n+--------------+-----------------+----------------+---------+--------------------------+--------------------------+-----------------------------------+\n|Silver Layer  |651              |349             |COMPLETED|2025-12-23 01:16:23.318448|2025-12-23 01:16:23.318448|Invalid records moved to quarantine|\n|Bronze Layer  |1000             |0               |COMPLETED|2025-12-23 01:16:18.628792|2025-12-23 01:16:18.628792|                                   |\n|Gold Layer    |30               |0               |COMPLETED|2025-12-23 01:16:27.271054|2025-12-23 01:16:27.271054|                                   |\n|Silver Layer  |0                |0               |STARTED  |2025-12-23 01:16:20.282073|2025-12-23 01:16:20.282073|                                   |\n|Bronze Layer  |0                |0               |STARTED  |2025-12-23 01:16:13.536841|2025-12-23 01:16:13.536841|                                   |\n|Gold Layer    |0                |0               |STARTED  |2025-12-23 01:16:25.143148|2025-12-23 01:16:25.143148|                                   |\n+--------------+-----------------+----------------+---------+--------------------------+--------------------------+-----------------------------------+\n\nIncremental load validation can be done by adding a test record and re-running pipeline.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "# 1. Validate Bronze Layer\n",
    "print(\"=== Bronze Layer Validation ===\")\n",
    "bronze_df = spark.read.table(\"workspace.default.bronze_sales_transactions\")\n",
    "bronze_count = bronze_df.count()\n",
    "print(f\"Bronze records count: {bronze_count}\")\n",
    "\n",
    "# 2. Validate Silver Layer\n",
    "print(\"=== Silver Layer Validation ===\")\n",
    "silver_df = spark.read.table(\"workspace.default.silver_sales_transactions\")\n",
    "silver_count = silver_df.count()\n",
    "print(f\"Silver valid records count: {silver_count}\")\n",
    "\n",
    "# Check for nulls or invalid total_amount\n",
    "invalid_total_df = silver_df.filter(col(\"total_amount\") != (col(\"quantity\") * col(\"unit_price\") - col(\"discount\")))\n",
    "invalid_count = invalid_total_df.count()\n",
    "print(f\"Silver records with incorrect total_amount: {invalid_count}\")\n",
    "\n",
    "# Quarantine table validation\n",
    "quarantine_df = spark.read.table(\"workspace.default.silver_sales_quarantine\")\n",
    "quarantine_count = quarantine_df.count()\n",
    "print(f\"Silver quarantined records count: {quarantine_count}\")\n",
    "\n",
    "# 3. Validate Gold Layer\n",
    "print(\"=== Gold Layer Validation ===\")\n",
    "gold_df = spark.read.table(\"workspace.default.gold_daily_sales\")\n",
    "gold_count = gold_df.count()\n",
    "print(f\"Gold records count: {gold_count}\")\n",
    "\n",
    "# Validate aggregation accuracy\n",
    "agg_total = gold_df.agg(spark_sum(\"total_daily_revenue\").alias(\"total_amount_gold\")).collect()[0][\"total_amount_gold\"]\n",
    "\n",
    "silver_total = silver_df.agg(spark_sum(\"total_amount\").alias(\"total_amount_silver\")).collect()[0][\"total_amount_silver\"]\n",
    "\n",
    "print(f\"Total amount in Silver: {silver_total}\")\n",
    "print(f\"Total amount in Gold: {agg_total}\")\n",
    "\n",
    "if abs(agg_total - silver_total) < 0.001:\n",
    "    print(\"Gold aggregation matches Silver totals\")\n",
    "else:\n",
    "    print(\"Discrepancy in Gold aggregation!\")\n",
    "\n",
    "# 4. Validate Logging\n",
    "print(\"=== Logging Validation ===\")\n",
    "logs_df = spark.read.table(\"workspace.default.pipeline_logs\")\n",
    "logs_df.show(truncate=False)\n",
    "\n",
    "# 5. Optional: Validate incremental load\n",
    "# Insert a small test record in Bronze, run Silver/Gold transformations, check counts\n",
    "print(\"Incremental load validation can be done by adding a test record and re-running pipeline.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Validation (1)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}