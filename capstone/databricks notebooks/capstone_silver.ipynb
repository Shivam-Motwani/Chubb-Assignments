{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bad82f8-0344-40d3-87fe-05d9f0870f25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"workspace.default.bronze_exports\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69c9c3b3-e9fb-4b07-8fe5-b5c346ddc32b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "df = df.withColumn(\n",
    "    \"valid_price\",\n",
    "    when((col(\"product_code\") == \"AGR\") & col(\"unit_price\").between(100, 2000), 1)\n",
    "    .when((col(\"product_code\") == \"TXT\") & col(\"unit_price\").between(200, 5000), 1)\n",
    "    .when((col(\"product_code\") == \"ELE\") & col(\"unit_price\").between(500, 20000), 1)\n",
    "    .when((col(\"product_code\") == \"AUT\") & col(\"unit_price\").between(10000, 80000), 1)\n",
    "    .when((col(\"product_code\") == \"PHA\") & col(\"unit_price\").between(20000, 200000), 1)\n",
    "    .when((col(\"product_code\") == \"OIL\") & col(\"unit_price\").between(20000, 120000), 1)\n",
    "    .when((col(\"product_code\") == \"MAC\") & col(\"unit_price\").between(5000, 50000), 1)\n",
    "    .otherwise(0)\n",
    ")\n",
    "\n",
    "df_silver = df.filter(col(\"valid_price\") == 1).drop(\"valid_price\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ac98327-55fd-47d7-a698-e2f93b1adf8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import initcap\n",
    "df_silver = df_silver.select(\n",
    "    \"export_id\",\n",
    "    \"country_code\",\n",
    "    initcap(\"country_name\").alias(\"country_name\"),\n",
    "    initcap(\"region\").alias(\"region\"),\n",
    "    \"product_code\",\n",
    "    initcap(\"product_name\").alias(\"product_name\"),\n",
    "    \"year\",\n",
    "    \"export_quantity\",\n",
    "    \"export_value_usd\",\n",
    "    \"unit_price\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "577968df-b74a-4c8e-bfd6-63238220262d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS workspace.default.silver_exports\")\n",
    "\n",
    "df_silver.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .saveAsTable(\"workspace.default.silver_exports\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6177255250723004,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "capstone_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}